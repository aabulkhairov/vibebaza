---
title: Web Scraping & Automation
description: Полный стек для веб-скрапинга и автоматизации браузера. Парсинг данных, мониторинг сайтов, автоматизация задач.
category: automation
tags:
  - Scraping
  - Automation
  - Browser
  - Data
  - Monitoring
featured: true
mcps:
  - firecrawl
  - puppeteer
  - browserbase
  - apify
  - brave-search
skills:
  - python-developer
  - typescript-expert
agents:
  - data-engineer
  - api-integration-specialist
prompts: []
---

## Для кого эта связка

Для разработчиков, аналитиков и маркетологов, которым нужно автоматизировать сбор данных с веб-сайтов.

## Что включено

### MCP-серверы

**Firecrawl** — продвинутый веб-краулер. Извлечение структурированных данных, обход защиты от ботов.

**Puppeteer** — автоматизация Chrome. Скриншоты, PDF, взаимодействие с динамическими страницами.

**Browserbase** — облачные браузеры для скрапинга. Масштабируемость, обход капчи.

**Apify** — платформа для веб-автоматизации. Готовые акторы, хранение данных.

**Brave Search** — поиск информации без отслеживания. Быстрый доступ к веб-контенту.

### Навыки

**Python Developer** — написание скриптов для обработки данных и автоматизации.

**TypeScript Expert** — разработка надежных инструментов для скрапинга.

### Агенты

**Data Engineer** — построение пайплайнов обработки данных.

**API Integration Specialist** — интеграция с внешними сервисами и API.

## Как использовать

1. **Определите источники** данных для сбора
2. **Настройте краулеры** с помощью Firecrawl или Puppeteer
3. **Обработайте данные** и сохраните в нужном формате
4. **Настройте мониторинг** для регулярного обновления

### Пример промпта

```
Напиши скрипт для Puppeteer, который:
- Заходит на страницу e-commerce
- Собирает названия, цены и рейтинги товаров
- Сохраняет данные в JSON
- Обрабатывает пагинацию
```

## Результат

- Автоматизированный сбор данных с любых сайтов
- Обход защиты от ботов
- Структурированные данные для анализа
- Регулярные обновления информации
