---
title: MLflow MCP сервер
description: Model Context Protocol сервер, который позволяет LLM взаимодействовать с серверами отслеживания MLflow через естественный язык для запроса экспериментов, анализа запусков, сравнения метрик и изучения реестра моделей.
tags:
- AI
- Analytics
- DevOps
- Monitoring
- Database
author: Community
featured: false
---

Model Context Protocol сервер, который позволяет LLM взаимодействовать с серверами отслеживания MLflow через естественный язык для запроса экспериментов, анализа запусков, сравнения метрик и изучения реестра моделей.

## Установка

### Используя uvx (Рекомендуется)

```bash
# Запустить напрямую без установки
uvx mlflow-mcp

# Или установить глобально
pip install mlflow-mcp
```

### Из исходников

```bash
git clone https://github.com/kkruglik/mlflow-mcp.git
cd mlflow-mcp
uv sync
uv run mlflow-mcp
```

## Конфигурация

### Claude Desktop

```json
{
  "mcpServers": {
    "mlflow": {
      "command": "uvx",
      "args": ["mlflow-mcp"],
      "env": {
        "MLFLOW_TRACKING_URI": "http://localhost:5000"
      }
    }
  }
}
```

## Доступные инструменты

| Инструмент | Описание |
|------|-------------|
| `get_experiments` | Список всех экспериментов |
| `get_experiment_by_name` | Получить эксперимент по имени |
| `get_experiment_metrics` | Найти все уникальные метрики |
| `get_experiment_params` | Найти все уникальные параметры |
| `get_runs` | Получить запуски с полными деталями. Поддерживает сортировку и пагинацию |
| `get_run` | Получить детальную информацию о конкретном запуске |
| `query_runs` | Фильтровать и сортировать запуски (например, "metrics.accuracy > 0.9", order_by="metrics.accuracy DESC") |
| `search_runs_by_tags` | Найти запуски по тегам с пагинацией |
| `get_run_metrics` | Получить все метрики для запуска |
| `get_run_metric` | Получить полную историю метрик с шагами |
| `get_run_artifacts` | Список артефактов (поддерживает просмотр директорий) |
| `get_run_artifact` | Скачать артефакт |
| `get_artifact_content` | Прочитать содержимое артефакта (text/json) |
| `get_best_run` | Найти лучший запуск по метрике (поддерживает специальные символы) |
| `compare_runs` | Сравнение бок о бок с полными данными |

## Возможности

- Управление экспериментами: Список и поиск экспериментов, обнаружение доступных метрик и параметров
- Анализ запусков: Получение деталей запусков, запросы с фильтрами, поиск лучших моделей
- Метрики и параметры: Получение истории метрик, сравнение параметров между запусками
- Артефакты: Просмотр и скачивание артефактов запусков
- Реестр моделей: Доступ к зарегистрированным моделям, версиям и стадиям развертывания
- Инструменты сравнения: Сравнение запусков бок о бок, выбор лучшего запуска
- Поиск по тегам: Фильтрация запусков по пользовательским тегам
- Пагинация: Пагинация на основе смещения для просмотра больших наборов результатов

## Переменные окружения

### Обязательные
- `MLFLOW_TRACKING_URI` - URL вашего сервера отслеживания MLflow (Примеры: http://localhost:5000, https://mlflow.company.com)

## Примеры использования

```
Покажи мне все эксперименты в MLflow
```

```
Какие 5 лучших запусков по точности в эксперименте 'my-experiment'?
```

```
Сравни запуски abc123 и def456
```

```
У какой модели самая высокая F1 оценка?
```

```
Покажи мне кривую потерь обучения для запуска xyz789
```

## Ресурсы

- [GitHub Repository](https://github.com/kkruglik/mlflow-mcp)

## Примечания

Требует Python >=3.10, MLflow >=3.4.0 и доступ к серверу отслеживания MLflow. MIT License.